{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexfazio/firecrawl-cookbook/blob/main/openai_o1_firecrawl_integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULHdYNR8QlPF"
      },
      "source": [
        "# Integrating OpenAI's o1 Reasoning Models with Firecrawl: A Step-by-Step Guide\n",
        "\n",
        "By Alex Fazio (https://twitter.com/alxfazio)\n",
        "\n",
        "Github repo: https://github.com/alexfazio/firecrawl-cookbook\n",
        "\n",
        "OpenAI has recently unveiled its o1 series models, marking a significant leap in the realm of complex reasoning with AI. These models are designed to \"think before they answer,\" producing extensive internal chains of thought before responding. In this guide, we'll explore how to integrate these powerful models into your applications, with a practical example of crawling a website using the o1-preview model.\n",
        "\n",
        "**This Jupyter notebook** demonstrates how to integrate OpenAI's o1 reasoning models with Firecrawl technology to perform complex tasks like crawling a website and extracting specific information.\n",
        "\n",
        "By the end of this notebook, you'll be able to:\n",
        "\n",
        "- Set up the Firecrawl and OpenAI environments\n",
        "- Use the o1-preview model to enhance the crawling process\n",
        "- Crawl a website and generate a list of relevant URLs based on a given objective\n",
        "- Extract content from crawled pages in Markdown\n",
        "- Evaluate the extracted content using the o1 reasoning model to check if it meets the specified objective\n",
        "\n",
        "This guide is designed for developers and data scientists who want to leverage advanced AI reasoning capabilities and web crawling technology to efficiently gather and analyze information from the web.\n",
        "\n",
        "## Requirements\n",
        "\n",
        "Before proceeding, ensure you have the following:\n",
        "\n",
        "- Firecrawl API key: Essential for accessing the Firecrawl service\n",
        "- OpenAI API key: Required for using the o1 reasoning models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sypSu88zQlPG"
      },
      "source": [
        "## Introduction to o1 Models\n",
        "\n",
        "The o1 models are large language models trained with reinforcement learning to excel in complex reasoning tasks. There are two models available:\n",
        "\n",
        "- **o1-preview**: An early preview designed for reasoning about hard problems using broad general knowledge.\n",
        "- **o1-mini**: A faster, cost-effective version ideal for coding, math, and science tasks that don't require extensive general knowledge.\n",
        "\n",
        "While these models offer significant advancements, they are not intended to replace GPT-4o in all use cases. If your application requires image inputs, function calling, or consistent fast response times, GPT-4o and GPT-4o mini remain the optimal choices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlPHD-WNQlPG"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "First, let's install the required libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "METpmDKFQlPH",
        "outputId": "b32a1fc8-b6ee-4268-e4b3-719a770d5a03"
      },
      "source": [
        "%pip install -q firecrawl-py openai python-dotenv"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/386.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m378.9/386.9 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/325.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzI4OO5EQlPH"
      },
      "source": [
        "## Step 1: Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEBEShvoQlPH"
      },
      "source": [
        "import os\n",
        "from firecrawl import FirecrawlApp\n",
        "import json\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKWKvisAQlPH"
      },
      "source": [
        "## Step 2: Load Environment Variables\n",
        "\n",
        "For Google Colab, we'll set the environment variables directly instead of using a .env file. In practice, you should never expose your API keys in your notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8vBvKDiQlPI"
      },
      "source": [
        "# For development, use environment variables\n",
        "os.environ['FIRECRAWL_API_KEY'] = 'your_firecrawl_api_key_here'\n",
        "os.environ['OPENAI_API_KEY'] = 'your_openai_api_key_here'\n",
        "\n",
        "# Retrieve API keys from environment variables\n",
        "firecrawl_api_key = os.getenv(\"FIRECRAWL_API_KEY\")\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jNb62ZnQlPI"
      },
      "source": [
        "## Step 3: Initialize the FirecrawlApp and OpenAI Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRUYdpUsQlPI"
      },
      "source": [
        "# Initialize the FirecrawlApp and OpenAI client\n",
        "app = FirecrawlApp(api_key=firecrawl_api_key)\n",
        "client = OpenAI(api_key=openai_api_key)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYIFGPKwQlPI"
      },
      "source": [
        "## Step 4: Define the Objective and URL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcEE8cljQlPI"
      },
      "source": [
        "url = \"https://example.com\"\n",
        "objective = \"Find the contact email for customer support\""
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oYsHFCzQlPI"
      },
      "source": [
        "## Step 5: Determine the Search Parameter Using o1-preview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIvi4bTRQlPI"
      },
      "source": [
        "map_prompt = f\"\"\"\n",
        "The map function generates a list of URLs from a website and accepts a search parameter. Based on the objective: {objective}, suggest a 1-2 word search parameter to find the needed information. Only respond with 1-2 words.\n",
        "\"\"\"\n",
        "\n",
        "# OpenAI API call\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"o1-preview\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": map_prompt}\n",
        "    ]\n",
        ")\n",
        "\n",
        "map_search_parameter = completion.choices[0].message.content.strip()\n",
        "print(f\"Search parameter: {map_search_parameter}\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrYCmYtEQlPI"
      },
      "source": [
        "## Step 6: Map the Website Using the Search Parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zir5O-HbQlPI"
      },
      "source": [
        "map_website = app.map_url(url, params={\"search\": map_search_parameter})\n",
        "print(\"Mapped URLs:\", map_website)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejGIGykTQlPI"
      },
      "source": [
        "## Step 7: Scrape the Top Pages and Check for the Objective"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZHYRT36QlPI"
      },
      "source": [
        "# Get top 3 links\n",
        "top_links = map_website[:3] if isinstance(map_website, list) else []\n",
        "\n",
        "for link in top_links:\n",
        "    # Scrape the page\n",
        "    scrape_result = app.scrape_url(link, params={'formats': ['markdown']})\n",
        "\n",
        "    # Check if objective is met\n",
        "    check_prompt = f\"\"\"\n",
        "    Given the following scraped content and objective, determine if the objective is met with high confidence.\n",
        "    If it is, extract the relevant information in a simple and concise JSON format.\n",
        "    If the objective is not met with high confidence, respond with 'Objective not met'.\n",
        "\n",
        "    Objective: {objective}\n",
        "    Scraped content: {scrape_result['markdown']}\n",
        "    \"\"\"\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"o1-preview\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": check_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    result = completion.choices[0].message.content.strip()\n",
        "\n",
        "    if result != \"Objective not met\":\n",
        "        try:\n",
        "            extracted_info = json.loads(result)\n",
        "            break\n",
        "        except json.JSONDecodeError:\n",
        "            continue\n",
        "else:\n",
        "    extracted_info = None"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNBIwUbhQlPJ"
      },
      "source": [
        "## Step 8: Display the Extracted Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ivv4ze9OQlPJ"
      },
      "source": [
        "if extracted_info:\n",
        "    print(\"Extracted Information:\")\n",
        "    print(json.dumps(extracted_info, indent=2))\n",
        "else:\n",
        "    print(\"Objective not met with the available content.\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39Sb3XlFQlPJ"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we've explored how to integrate OpenAI's new o1 reasoning models into your applications to perform complex tasks like crawling a website and extracting specific information. The o1 models showcase impressive capabilities in reasoning and problem-solving, making them valuable tools for developers tackling challenging AI tasks.\n",
        "\n",
        "Whether you're working on advanced coding problems, mathematical computations, or intricate scientific queries, the o1 models can significantly enhance your application's reasoning abilities.\n",
        "\n",
        "Happy coding!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
