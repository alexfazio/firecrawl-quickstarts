2024-12-24 11:33:44,291 - INFO - <module> - Using OpenAI version: 1.58.1
2024-12-24 11:41:04,788 - INFO - <module> - Using OpenAI version: 1.58.1
2024-12-24 11:44:08,887 - INFO - <module> - Using OpenAI version: 1.58.1
2024-12-24 11:46:05,787 - INFO - <module> - Using OpenAI version: 1.58.1
2024-12-24 11:51:12,640 - INFO - <module> - Using OpenAI version: 1.58.1
2024-12-24 11:53:36,142 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:53:36,143 - INFO - belongs_to_category - Analyzing paper: 'K-Level Reasoning with Large Language Models' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:53:39,858 - INFO - belongs_to_category - Classification result: belongs=True, confidence=0.85
2024-12-24 11:53:39,858 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:53:41,093 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:53:41,093 - INFO - belongs_to_category - Analyzing paper: 'EVA-GAN: Enhanced Various Audio Generation via Scalable Generative  Adversarial Networks' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:53:41,811 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 11:53:41,812 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:53:42,525 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:53:42,525 - INFO - belongs_to_category - Analyzing paper: 'Repeat After Me: Transformers are Better than State Space Models at Copying' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:53:43,979 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 11:53:43,979 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:53:45,045 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:53:45,045 - INFO - belongs_to_category - Analyzing paper: 'Boximator: Generating Rich and Controllable Motions for Video Synthesis' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:53:45,842 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 11:53:45,843 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:53:46,622 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:53:46,622 - INFO - belongs_to_category - Analyzing paper: 'PokéLLMon: A Human-Parity Agent for Pokémon Battles with Large  Language Models' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:53:47,640 - INFO - belongs_to_category - Classification result: belongs=True, confidence=0.95
2024-12-24 11:53:47,641 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:54:07,578 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:54:07,578 - INFO - belongs_to_category - Analyzing paper: 'Nomic Embed: Training a Reproducible Long Context Text Embedder' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:54:08,678 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 11:54:08,679 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:54:09,542 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:54:09,543 - INFO - belongs_to_category - Analyzing paper: 'Specialized Language Models with Cheap Inference from Limited Domain Data' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:54:10,407 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 11:54:10,408 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:54:11,176 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:54:11,177 - INFO - belongs_to_category - Analyzing paper: 'StepCoder: Improve Code Generation with Reinforcement Learning from Compiler Feedback' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:54:12,008 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.75
2024-12-24 11:54:12,008 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:54:12,635 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:54:12,635 - INFO - belongs_to_category - Analyzing paper: 'Moonshot: Towards Controllable Video Generation and Editing with Multimodal Conditions' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:54:13,442 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 11:54:13,442 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:54:14,086 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:54:14,086 - INFO - belongs_to_category - Analyzing paper: 'FlowVid: Taming Imperfect Optical Flows for Consistent Video-to-Video  Synthesis' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:54:14,902 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 11:54:14,904 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:54:23,019 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:54:23,019 - INFO - belongs_to_category - Analyzing paper: 'LOCOST: State-Space Models for Long Document Abstractive Summarization' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:54:23,805 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 11:54:23,806 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:54:25,063 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:54:25,063 - INFO - belongs_to_category - Analyzing paper: 'TravelPlanner: A Benchmark for Real-World Planning with Language Agents' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:54:25,683 - INFO - belongs_to_category - Classification result: belongs=True, confidence=0.85
2024-12-24 11:54:25,684 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:54:27,018 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:54:27,018 - INFO - belongs_to_category - Analyzing paper: 'Motion-Zero: Zero-Shot Moving Object Control Framework for  Diffusion-Based Video Generation' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:54:27,769 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 11:54:27,770 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:54:28,634 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:54:28,635 - INFO - belongs_to_category - Analyzing paper: 'The Impact of Reasoning Step Length on Large Language Models' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:54:29,396 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.8
2024-12-24 11:54:29,397 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:54:38,000 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:54:38,000 - INFO - belongs_to_category - Analyzing paper: 'Can Transformers Learn Sequential Function Classes In Context?' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:54:38,897 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 11:54:38,898 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:54:39,712 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:54:39,712 - INFO - belongs_to_category - Analyzing paper: 'In-Context Language Learning: Architectures and Algorithms' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:54:40,387 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 11:54:40,387 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:54:41,629 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:54:41,630 - INFO - belongs_to_category - Analyzing paper: 'PEEKABOO: Interactive Video Generation via Masked-Diffusion' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:54:42,586 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 11:54:42,587 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:54:43,285 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:54:43,286 - INFO - belongs_to_category - Analyzing paper: 'Large Language Models Are Neurosymbolic Reasoners' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:54:44,104 - INFO - belongs_to_category - Classification result: belongs=True, confidence=0.85
2024-12-24 11:54:44,105 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:54:45,375 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:54:45,376 - INFO - belongs_to_category - Analyzing paper: 'Transformers are Multi-State RNNs' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:54:46,205 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 11:54:46,206 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:54:55,692 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:54:55,692 - INFO - belongs_to_category - Analyzing paper: 'MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:54:56,587 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 11:54:56,588 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:54:57,375 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:54:57,375 - INFO - belongs_to_category - Analyzing paper: 'MotionCrafter: One-Shot Motion Customization of Diffusion Models' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:54:58,042 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 11:54:58,042 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:54:58,928 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:54:58,928 - INFO - belongs_to_category - Analyzing paper: '' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:54:59,652 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.0
2024-12-24 11:54:59,652 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:55:00,864 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:55:00,864 - INFO - belongs_to_category - Analyzing paper: 'Paper not found' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:55:01,647 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.0
2024-12-24 11:55:01,647 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:55:02,412 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:55:02,412 - INFO - belongs_to_category - Analyzing paper: 'Paper not found' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:55:03,106 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.0
2024-12-24 11:55:03,106 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:55:12,187 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:55:12,188 - INFO - belongs_to_category - Analyzing paper: '' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:55:13,045 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.0
2024-12-24 11:55:13,045 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:55:13,803 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:55:13,803 - INFO - belongs_to_category - Analyzing paper: 'Paper not found' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:55:14,578 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.0
2024-12-24 11:55:14,579 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 11:55:15,375 - INFO - wrapper - Entering belongs_to_category
2024-12-24 11:55:15,375 - INFO - belongs_to_category - Analyzing paper: '' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 11:55:16,117 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.0
2024-12-24 11:55:16,117 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:08:56,375 - INFO - <module> - Using OpenAI version: 1.58.1
2024-12-24 12:10:37,031 - INFO - <module> - Using OpenAI version: 1.58.1
2024-12-24 12:11:29,538 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:11:29,539 - INFO - belongs_to_category - Analyzing paper: 'Leveraging Reinforcement Learning and Large Language Models for Code Optimization' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:11:30,702 - INFO - belongs_to_category - Classification result: belongs=True, confidence=0.75
2024-12-24 12:11:30,703 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:11:46,989 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:11:46,993 - INFO - belongs_to_category - Analyzing paper: 'TDD Without Tears: Towards Test Case Generation from Requirements through Deep Reinforcement Learning' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:11:47,851 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.7
2024-12-24 12:11:47,852 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:11:48,525 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:11:48,525 - INFO - belongs_to_category - Analyzing paper: 'Planning, Creation, Usage: Benchmarking LLMs for Comprehensive Tool Utilization in Real-World Complex Scenarios' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:11:49,362 - INFO - belongs_to_category - Classification result: belongs=True, confidence=0.95
2024-12-24 12:11:49,362 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:11:50,367 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:11:50,367 - INFO - belongs_to_category - Analyzing paper: 'Cooperation on the Fly: Exploring Language Agents for Ad Hoc Teamwork in  the Avalon Game' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:11:50,970 - INFO - belongs_to_category - Classification result: belongs=True, confidence=0.85
2024-12-24 12:11:50,970 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:11:51,998 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:11:51,998 - INFO - belongs_to_category - Analyzing paper: 'IRCoCo: Immediate Rewards-Guided Deep Reinforcement Learning for Code  Completion' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:11:52,660 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 12:11:52,660 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:12:01,753 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:12:01,754 - INFO - belongs_to_category - Analyzing paper: 'On the Prospects of Incorporating Large Language Models (LLMs) in  Automated Planning and Scheduling (APS)' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:12:02,607 - INFO - belongs_to_category - Classification result: belongs=True, confidence=0.75
2024-12-24 12:12:02,608 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:12:03,227 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:12:03,227 - INFO - belongs_to_category - Analyzing paper: 'RePLan: Robotic Replanning with Perception and Language Models' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:12:06,332 - INFO - belongs_to_category - Classification result: belongs=True, confidence=0.85
2024-12-24 12:12:06,333 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:12:07,370 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:12:07,370 - INFO - belongs_to_category - Analyzing paper: 'Instruction Fusion: Advancing Prompt Evolution through Hybridization' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:12:08,152 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.75
2024-12-24 12:12:08,153 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:12:17,722 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:12:17,722 - INFO - belongs_to_category - Analyzing paper: 'From LLM to Conversational Agent: A Memory Enhanced Architecture with  Fine-Tuning of Large Language Models' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:12:18,481 - INFO - belongs_to_category - Classification result: belongs=True, confidence=0.85
2024-12-24 12:12:18,481 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:12:19,545 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:12:19,546 - INFO - belongs_to_category - Analyzing paper: 'Language Models, Agent Models, and World Models: The LAW for Machine  Reasoning and Planning' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:12:20,343 - INFO - belongs_to_category - Classification result: belongs=True, confidence=0.85
2024-12-24 12:12:20,343 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:12:22,296 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:12:22,296 - INFO - belongs_to_category - Analyzing paper: 'CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent  Evaluation' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:12:23,084 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.8
2024-12-24 12:12:23,085 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:12:35,257 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:12:35,257 - INFO - belongs_to_category - Analyzing paper: 'SwarmBrain: Embodied agent for real-time strategy game StarCraft II via large language models' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:12:36,216 - INFO - belongs_to_category - Classification result: belongs=True, confidence=0.85
2024-12-24 12:12:36,217 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:12:37,987 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:12:37,987 - INFO - belongs_to_category - Analyzing paper: 'Paper not found' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:12:38,723 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.0
2024-12-24 12:12:38,723 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:34:19,232 - INFO - <module> - Using OpenAI version: 1.58.1
2024-12-24 12:35:06,663 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:35:06,664 - INFO - belongs_to_category - Analyzing paper: 'Does Gaussian Splatting need SFM Initialization?' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:35:07,922 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.1
2024-12-24 12:35:07,923 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:35:08,561 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:35:08,561 - INFO - belongs_to_category - Analyzing paper: 'LLM-R2: A Large Language Model Enhanced Rule-based Rewrite System for  Boosting Query Efficiency' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:35:09,268 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 12:35:09,270 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:35:09,959 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:35:09,959 - INFO - belongs_to_category - Analyzing paper: 'How Far Can We Go with Practical Function-Level Program Repair?' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:35:10,861 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.75
2024-12-24 12:35:10,861 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:35:11,492 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:35:11,493 - INFO - belongs_to_category - Analyzing paper: 'AutoCrawler: A Progressive Understanding Web Agent for Web Crawler Generation' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:35:12,209 - INFO - belongs_to_category - Classification result: belongs=True, confidence=0.85
2024-12-24 12:35:12,210 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:35:13,456 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:35:13,463 - INFO - belongs_to_category - Analyzing paper: 'PhysDreamer: Physics-Based Interaction with 3D Objects via Video Generation' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:35:14,254 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 12:35:14,255 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:35:26,077 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:35:26,079 - INFO - belongs_to_category - Analyzing paper: 'Groma: Localized Visual Tokenization for Grounding Multimodal Large Language Models' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:35:26,885 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.7
2024-12-24 12:35:26,886 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:35:27,520 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:35:27,520 - INFO - belongs_to_category - Analyzing paper: 'TextSquare: Scaling up Text-Centric Visual Instruction Tuning' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:35:28,251 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 12:35:28,252 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:35:28,881 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:35:28,889 - INFO - belongs_to_category - Analyzing paper: 'Metasql: A Generate-then-Rank Framework for Natural Language to SQL  Translation' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:35:29,525 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 12:35:29,526 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:35:30,148 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:35:30,149 - INFO - belongs_to_category - Analyzing paper: 'PET-SQL: A Prompt-enhanced Two-stage Text-to-SQL Framework with  Cross-consistency' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:35:30,831 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 12:35:30,831 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:35:31,454 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:35:31,454 - INFO - belongs_to_category - Analyzing paper: 'Query Rewriting via Large Language Models' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:35:32,257 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.75
2024-12-24 12:35:32,257 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:35:49,837 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:35:49,837 - INFO - belongs_to_category - Analyzing paper: 'CoderUJB: An Executable and Unified Java Benchmark for Practical  Programming Scenarios' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:35:50,621 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.7
2024-12-24 12:35:50,623 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:35:51,287 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:35:51,287 - INFO - belongs_to_category - Analyzing paper: 'A Deep Dive into Large Language Models for Automated Bug Localization and Repair' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:35:52,082 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.8
2024-12-24 12:35:52,083 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:35:52,778 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:35:52,778 - INFO - belongs_to_category - Analyzing paper: 'Spec-Gaussian: Anisotropic View-Dependent Appearance for 3D Gaussian Splatting' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:35:53,613 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.95
2024-12-24 12:35:53,614 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:35:54,271 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:35:54,272 - INFO - belongs_to_category - Analyzing paper: 'On the Multi-turn Instruction Following for Conversational Web Agents' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:35:55,069 - INFO - belongs_to_category - Classification result: belongs=True, confidence=0.85
2024-12-24 12:35:55,072 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:35:56,159 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:35:56,160 - INFO - belongs_to_category - Analyzing paper: 'AutoGuide: Automated Generation and Selection of State-Aware Guidelines for Large Language Model Agents' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:35:56,827 - INFO - belongs_to_category - Classification result: belongs=True, confidence=0.85
2024-12-24 12:35:56,828 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:36:07,420 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:36:07,422 - INFO - belongs_to_category - Analyzing paper: 'AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:36:08,867 - INFO - belongs_to_category - Classification result: belongs=True, confidence=0.85
2024-12-24 12:36:08,868 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:36:09,933 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:36:09,933 - INFO - belongs_to_category - Analyzing paper: 'VisualWebBench: How Far Have Multimodal LLMs Evolved in Web Page Understanding and Grounding?' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:36:11,050 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.7
2024-12-24 12:36:11,051 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:36:11,703 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:36:11,704 - INFO - belongs_to_category - Analyzing paper: 'PURPLE: Making a Large Language Model a Better SQL Writer' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:36:12,524 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.75
2024-12-24 12:36:12,525 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:36:13,199 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:36:13,199 - INFO - belongs_to_category - Analyzing paper: 'PhysAvatar: Learning the Physics of Dressed 3D Avatars from Visual Observations' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:36:13,913 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.85
2024-12-24 12:36:13,913 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:36:14,581 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:36:14,581 - INFO - belongs_to_category - Analyzing paper: 'Learning to Use Tools via Cooperative and Interactive Agents' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:36:15,221 - INFO - belongs_to_category - Classification result: belongs=True, confidence=0.85
2024-12-24 12:36:15,221 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:36:22,055 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:36:22,055 - INFO - belongs_to_category - Analyzing paper: 'Paper not found' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:36:22,958 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.0
2024-12-24 12:36:22,958 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:36:23,577 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:36:23,577 - INFO - belongs_to_category - Analyzing paper: '' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:36:24,314 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.0
2024-12-24 12:36:24,314 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:36:24,944 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:36:24,945 - INFO - belongs_to_category - Analyzing paper: 'Paper not found' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:36:25,724 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.0
2024-12-24 12:36:25,724 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:36:26,344 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:36:26,344 - INFO - belongs_to_category - Analyzing paper: 'Paper not found' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:36:27,046 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.0
2024-12-24 12:36:27,046 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:36:27,663 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:36:27,663 - INFO - belongs_to_category - Analyzing paper: 'Paper not found' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:36:28,346 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.0
2024-12-24 12:36:28,349 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:36:46,180 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:36:46,180 - INFO - belongs_to_category - Analyzing paper: 'Paper not found' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:36:47,038 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.0
2024-12-24 12:36:47,038 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:36:47,675 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:36:47,675 - INFO - belongs_to_category - Analyzing paper: 'Paper not found' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:36:48,497 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.0
2024-12-24 12:36:48,497 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:36:49,090 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:36:49,090 - INFO - belongs_to_category - Analyzing paper: '' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:36:49,908 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.0
2024-12-24 12:36:49,908 - INFO - wrapper - Exiting belongs_to_category successfully
2024-12-24 12:36:50,533 - INFO - wrapper - Entering belongs_to_category
2024-12-24 12:36:50,533 - INFO - belongs_to_category - Analyzing paper: 'Paper not found' for category '
**Definition of “AI Agents”**
An "AI Agent" is any system in which a large language model (LLM):
    1. Maintains Dynamic Control over how tasks are accomplished, including
       which tools or APIs are used and in what sequence.
    2. Plans, Reasons, and Adapts its approach based on user goals and
       feedback from its environment (e.g., tool outputs, code execution,
       external data).
    3. Acts Autonomously or Semi-Autonomously in open-ended or complex tasks
       that cannot be fully decomposed in advance.
    4. Demonstrates Decision-Making beyond hardcoded or strictly
       human-defined workflow paths, such as deciding what to do next at
       each step (versus executing a single, fixed script).

**Core Criterion for Classification**
A white paper belongs to the “AI Agents” category if its primary focus
describes, evaluates, measures, or demonstrates LLM-based systems that
exhibit or aim to exhibit one or more of the above qualities. This includes
systems that:
    • Show Partial, Incremental, or Full Autonomy in real-world or
      simulated tasks.
    • Employ LLMs to Dynamically Decide how to use tools (e.g., web
      browsing, code writing, system commands).
    • Investigate, Benchmark, or Compare the performance of such agentic
      systems, even if only a subset of tasks is completed autonomously.
    • Provide Frameworks for Building or Testing agentic capabilities in
      LLMs (e.g., multi-step planning, chain-of-thought reasoning,
      environment/tool usage).

**Clarifications to Prevent Underclassification**
    • Partial Autonomy Counts: Papers need not demonstrate 100% autonomous
      task completion. Even if an LLM handles only a fraction of tasks
      without human intervention, it can still qualify if the system’s
      goal or design involves adaptive or autonomous capabilities.
    • Research or Benchmarking is Included: Papers that focus on measuring,
      experimenting with, or benchmarking LLM agents should be classified
      as “AI Agents” if they revolve around agentic behavior, even if the
      research finds current systems are limited or only partially
      successful.
    • Use of Tools or Environment: If the paper describes LLMs selecting
      and executing code, commands, or API calls at their own discretion
      (i.e., not merely a single-step prompt for code generation), it
      likely falls under agentic systems.
    • Evaluation of Agent Performance: Studies that assess the
      effectiveness, reliability, or scalability of AI agents in performing
      tasks should be included if they address the agent’s ability to
      autonomously manage and execute tasks.
    • Integration with External Systems: Papers that explore how AI agents
      interact with external systems, databases, or APIs to accomplish
      tasks should be considered relevant.

**Exclusion Criterion**
A paper should not be classified under “AI Agents” if it only:
    • Discusses Static or Single-Step LLM Prompts that generate answers,
      translations, or content without autonomy or iterative
      decision-making.
    • Describes Purely Human-Orchestrated Pipelines where the LLM’s role is
      strictly predefined at each step (no dynamic path-finding, tool
      selection, or open-ended planning).
    • Focuses on General LLM Usage (e.g., chatbots, Q&A systems) without
      discussing autonomy, adaptive behavior, or iterative tool usage.

**Likely Categories for Agentic Systems Papers**
Based on Anthropic’s blog post, these arXiv categories are the most likely
homes for papers on agentic LLM systems:
    • Multiagent Systems (cs.MA) – Most directly relevant
    • Artificial Intelligence (cs.AI)
    • Computation and Language (cs.CL)
    • Machine Learning (cs.LG)
    • Human-Computer Interaction (cs.HC)
    • Software Engineering (cs.SE)
'
2024-12-24 12:36:51,314 - INFO - belongs_to_category - Classification result: belongs=False, confidence=0.0
2024-12-24 12:36:51,314 - INFO - wrapper - Exiting belongs_to_category successfully
